{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATION DES MODULES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "##### UNCOMMENT THIS SECTION IF FIRT TIME RUNNING\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "#####\n",
    "\n",
    "# Set seed for random results base calculation\n",
    "np.random.seed(500)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe des avis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously made to show famous 1950s stripper M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film was more effective in persuading me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unless you are already familiar with the pop s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From around the time Europe began fighting Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not surprised that even cowgirls get the bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis\n",
       "0  Obviously made to show famous 1950s stripper M...\n",
       "1  This film was more effective in persuading me ...\n",
       "2  Unless you are already familiar with the pop s...\n",
       "3  From around the time Europe began fighting Wor...\n",
       "4  Im not surprised that even cowgirls get the bl..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe des scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score\n",
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe merged\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously made to show famous 1950s stripper M...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film was more effective in persuading me ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unless you are already familiar with the pop s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From around the time Europe began fighting Wor...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not surprised that even cowgirls get the bl...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis  Score\n",
       "0  Obviously made to show famous 1950s stripper M...     -1\n",
       "1  This film was more effective in persuading me ...     -1\n",
       "2  Unless you are already familiar with the pop s...     -1\n",
       "3  From around the time Europe began fighting Wor...     -1\n",
       "4  Im not surprised that even cowgirls get the bl...     -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LECTURE DES FICHIERS\n",
    "print(\"\\nDataframe des avis\")\n",
    "df_avis = pd.read_csv('Dataset/dataset.csv', sep = '\\t', header = None, names = ['Avis'], encoding ='utf-8')\n",
    "display(df_avis.head())\n",
    "display(df_avis.shape)\n",
    "\n",
    "print(\"\\nDataframe des scores\")\n",
    "df_score = pd.read_csv('Dataset/labels.csv', sep = '\\t', header = None, names = ['Score'], encoding ='utf-8')\n",
    "display(df_score.head())\n",
    "display(df_score.shape)\n",
    "\n",
    "print(\"\\nDataframe merged\")\n",
    "df = df_avis.join(df_score)\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After having read two or three negative review...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently (May 2008) discovered that this chi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pathetic is the word. Bad acting, pathetic scr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spencer Tracy and Katherine Hepburn would roll...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This in my opinion is one of the best action m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis  Score\n",
       "0  After having read two or three negative review...      1\n",
       "1  I recently (May 2008) discovered that this chi...      1\n",
       "2  Pathetic is the word. Bad acting, pathetic scr...     -1\n",
       "3  Spencer Tracy and Katherine Hepburn would roll...     -1\n",
       "4  This in my opinion is one of the best action m...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copie du DF originale\n",
    "df2 = shuffle(df)\n",
    "# Réinitialisation des index\n",
    "#df2.reset_index()\n",
    "df2.reset_index(inplace = True, \n",
    "                drop = True)\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DÉFINITION DES CONSTANTES UTILISÉES\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "STOP_WORDS_EXCEPTIONS = set(('not',))\n",
    "\n",
    "#dictionnaire des POS-Tags\n",
    "POS_TAG_MAP = defaultdict(lambda : wn.NOUN)\n",
    "POS_TAG_MAP['J'] = wn.ADJ\n",
    "POS_TAG_MAP['V'] = wn.VERB\n",
    "POS_TAG_MAP['R'] = wn.ADV\n",
    "\n",
    "#DÉFINITION DES FONCTIONS DE PRÉTRAITEMENTS\n",
    "def replace_contractions(document):\n",
    "    \"\"\"\n",
    "    replaces contracted expressions in a document\n",
    "    \n",
    "    returns document with no contracted expressions\n",
    "    \"\"\"\n",
    "    return contractions.fix(document)\n",
    "\n",
    "def remove_non_ascii(tokens):\n",
    "    '''\n",
    "    normalizes the tokens\n",
    "    encodes tokens as ASCII characters from tokens\n",
    "    and decodes as utf-8\n",
    "    \n",
    "    returns a list of normalized and encoded as ascii tokens\n",
    "    '''\n",
    "    return [unicodedata.normalize('NFKD', token)\n",
    "           .encode('ascii', 'ignore')\n",
    "           .decode('utf-8', 'ignore')\n",
    "           for token in tokens]\n",
    "\n",
    "def to_lowercase(tokens):\n",
    "    \"\"\"returns a list of tokens in lowercase\"\"\"\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "def replace_numbers(tokens):\n",
    "    \"\"\"\n",
    "    replaces tokens representing whole numeric values\n",
    "    by their equivalent letter values\n",
    "    \n",
    "    returns a list of transformed tokens\n",
    "    \"\"\"\n",
    "    engine = inflect.engine()\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        new_token = token\n",
    "        if token.isdigit():\n",
    "            new_token = engine.number_to_words(token)\n",
    "        new_tokens.append(new_token)\n",
    "    return new_tokens\n",
    "\n",
    "def remove_punctuation(tokens):\n",
    "    \"\"\"\n",
    "    removes tokens not in \\w and \\s classes of characters.\n",
    "    by extension, all punctuation characters will be removed\n",
    "    \n",
    "    returns a list of tokens only in \\w and \\s\n",
    "    \"\"\"\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        new_token = re.sub(r'[^\\w\\s]', '', token)\n",
    "        if new_token != '':\n",
    "            new_tokens.append(new_token)\n",
    "    return new_tokens\n",
    "\n",
    "def remove_stopwords(tokens, stopwords, exceptions):\n",
    "    '''\n",
    "    removes all stopwords (a set) from tokens (a list)\n",
    "    except those in exceptions (a set)\n",
    "    \n",
    "    returns a list of tokens that are not stopwords\n",
    "    '''\n",
    "    stop = stopwords - exceptions\n",
    "    return [token for token in tokens if token not in stop]\n",
    "\n",
    "def lemmatize(tokens, lemmatizer, pos_tag_map):\n",
    "    '''\n",
    "    lematizes all tokens using a lemmatizer and a POS-Tagging map\n",
    "    \n",
    "    returns the list of lemmatized tokens\n",
    "    '''\n",
    "    return [lemmatizer.lemmatize(token, pos_tag_map[tag[0]]) for token, tag in pos_tag(tokens)]\n",
    "    \n",
    "def normalize(tokens):\n",
    "    '''\n",
    "    normalizes all the tokens by using all preprocessing\n",
    "    functions taking a list of tokens as input\n",
    "    \n",
    "    returns the list of normalized tokens\n",
    "    '''\n",
    "    tokens = remove_non_ascii(tokens)\n",
    "    tokens = to_lowercase(tokens)\n",
    "    tokens = replace_numbers(tokens)\n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_stopwords(tokens, STOP_WORDS, STOP_WORDS_EXCEPTIONS)\n",
    "    tokens = lemmatize(tokens, WordNetLemmatizer(), POS_TAG_MAP)\n",
    "    return tokens\n",
    "\n",
    "def preprocess(document):\n",
    "    document = replace_contractions(document) #remplacement des contractions dans le document\n",
    "    tokens = word_tokenize(document) #list des tokens du document\n",
    "    tokens = normalize(tokens) #list des tokens normalisés du document\n",
    "    document = ''.join([\" \" + token for token in tokens]).strip() #rejoindre les tokens normalisés pour obtenir le document nettoyé \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    read two three negative review main page imdb ...\n",
       "1    recently may two thousand and eight discover c...\n",
       "2    pathetic word bad act pathetic script cheezy d...\n",
       "3    spencer tracy katherine hepburn would roll gra...\n",
       "4    opinion one best action movie 1970s not featur...\n",
       "Name: Avis, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preprocessing dataset\n",
    "df_test = df2.copy()\n",
    "df_test['Avis'] = [preprocess(document) for document in df_test['Avis']]\n",
    "display(df_test['Avis'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
