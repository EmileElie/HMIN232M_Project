\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
% Nicer default font (+ math font) than Computer Modern for most use cases
\usepackage{mathpazo}
% Basic figure setup, for now with no caption control since it's done
% automatically by Pandoc (which extracts ![](path) syntax from Markdown).
\usepackage{graphicx}
% We will generate all images so they have a width \maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
% Set max figure width to be 80% of text width, for now hardcoded.
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
% Ensure that by default, figures have no caption (until we provide a
% proper Figure object with a Caption API and a way to capture that
% in the conversion process - todo).
\usepackage{caption}
\DeclareCaptionLabelFormat{nolabel}{}
\captionsetup{labelformat=nolabel}
\usepackage{adjustbox} % Used to constrain images to a maximum size
\usepackage{xcolor} % Allow colors to be defined
\usepackage{enumerate} % Needed for markdown enumerations to work
\usepackage{geometry} % Used to adjust the document margins
\usepackage{amsmath} % Equations
\usepackage{amssymb} % Equations
\usepackage{textcomp} % defines textquotesingle
% Hack from http://tex.stackexchange.com/a/47451/13684:
\AtBeginDocument{%
    \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
}
\usepackage{upquote} % Upright quotes for verbatim code
\usepackage{eurosym} % defines \euro
\usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
\usepackage[utf8]{inputenc} % Allow utf-8 characters in the tex document
\usepackage{fancyvrb} % verbatim replacement that allows latex
\usepackage{grffile} % extends the file name processing of package graphics
                     % to support a larger range
% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}
\usepackage{longtable} % longtable support required by pandoc >1.10
\usepackage{booktabs}  % table support for pandoc > 1.12.2
\usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
\usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                            % normalem makes italics be italics, not underlines
\usepackage{mathrsfs}
\usepackage{listingsutf8}

\lstset{
  language=Python,
  commentstyle=\color{red!80}\upshape,
  keywordstyle=\color{blue!60},
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{gray!10}, %code with gray background
  rulecolor=\color{black!30},
  numberstyle=\footnotesize, %line numbers for the code
  numbers=left, %numbers to the left
  breaklines=true,
  breakatwhitespace=true,
  showstringspaces=false,
  stringstyle=\color{purple},
  tabsize=3,
  frame=single,
  framextopmargin=2pt,
  framexbottommargin=2pt,
  captionpos=b,
  inputencoding=utf8,
  extendedchars=true, %to extend the default charset
  literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1 {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1 {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1 {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1 {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1 {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1 {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1 {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1 {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1 {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1 {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
}

% Colors for the hyperref package
\definecolor{urlcolor}{rgb}{0,.145,.698}
\definecolor{linkcolor}{rgb}{.71,0.21,0.01}
\definecolor{citecolor}{rgb}{.12,.54,.11}

% ANSI colors
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}
\definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
\definecolor{ansi-default-inverse-bg}{HTML}{000000}

% commands and environments needed by pandoc snippets
% extracted from the output of `pandoc -s`
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}

% Additional commands for more recent versions of Pandoc
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}

% Define a nice break command that doesn't care if a line doesn't already
% exist.
\def\br{\hspace*{\fill} \\* }
% Math Jax compatibility definitions
\def\gt{>}
\def\lt{<}
\let\Oldtex\TeX
\let\Oldlatex\LaTeX
\renewcommand{\TeX}{\textrm{\Oldtex}}
\renewcommand{\LaTeX}{\textrm{\Oldlatex}}
% Document parameters
% Document title
\title{Construction des classifieurs}

% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother

% Exact colors from NB
\definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
\definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}

\author{
  \textbf{Bachar \textsc{Rima}} \and
  \textbf{Emile \textsc{Youssef}} \and
  \textbf{Tasnim \textsc{Shaqura}}
}

% Prevent overflowing lines due to hard-to-break entities
\sloppy
% Setup hyperref package
\hypersetup{
  breaklinks=true,  % so long urls are correctly broken across lines
  colorlinks=true,
  urlcolor=urlcolor,
  linkcolor=linkcolor,
  citecolor=citecolor,
  }
% Slightly bigger margins than the latex defaults
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}

\begin{document}
\maketitle
\tableofcontents
\newpage

\hypertarget{projet---classification-de-documents-dopinions}{%
\section{Résumé du projet}\label{projet---classification-de-documents-dopinions}}
\begin{itemize}
\tightlist
\item
  Un jeu de données textuelles est mis à disposition sur Moodle.\\
\item
  Il s'agit d'un corpus de 10.000 documents contenant des avis
  d'internautes sur des films.\\
\item
  A chaque document est associé sa polarité selon l'avis (+1 : positif,
  -1 : négatif).\\
\item
  Le fichier des documents est formaté dans un tableau csv (un avis par
  ligne), un autre fichier csv contient les polarités d'avis par
  document (-1/+1).\\
\item
  Une correspondance directe existe entre les numéros des lignes des
  documents et des polarités.
\end{itemize}

\hypertarget{aperuxe7u-du-module-utility_ml.py}{%
\section{Aperçu du module
utility\_ML.py}\label{aperuxe7u-du-module-utility_ml.py}}
Le module \texttt{utility\_ML.py} est utilisé pour externalizer les
éléments de programmation utilitaires utilisées tout au long de notre
projet. Ceci inclut :

\begin{enumerate}
  \item Des \textbf{constantes} désignant des chemins
  vers les \textbf{ressources utilisées/créées} par le projet
  (\emph{datasets, fichiers pickle, etc.})
  \item Des \textbf{constantes}
  désignant des \textbf{objets} utilisés dans le code du projet
  (\emph{e.g.~STOP\_WORDS, POS\_TAG\_MAP, valeurs de paramétrage des
  fonctions utilisés dans le projet, etc.})
  \item Des \textbf{fonctions
  wrapper} pour les fonctions d'\textbf{importation}, de \textbf{fusion} et de \textbf{mélange} de
  datasets
  \item Des \textbf{fonctions de prétraitement}
  (\emph{e.g.~remplacement des contractions, suppression de ponctuation,
  lemmatization, etc.})
  \item Des \textbf{classes utilitaires} utilisées
 dans le projet (\emph{e.g.~classe encapsulant les résultats d'une recherche
 par \texttt{GridSearch}})
\end{enumerate}

\lstinputlisting{source/utility_ML.py}

\hypertarget{importation-des-modules-et-configuration-de-lenvironnement-de-travail}{%
\section{Importation des modules et configuration de
l'environnement de
travail}\label{importation-des-modules-et-configuration-de-lenvironnement-de-travail}}
Outre les modules essentiels pour faire du machine learning, on importe
le fichier \texttt{utility\_ML.py} contenant l'ensemble des constantes,
ressources, fonctions de prétraitement, et classes utilitaires définies.

\lstinputlisting{source/modules.py}

\hypertarget{importation-des-datasets}{%
\section{Importation des
datasets}\label{importation-des-datasets}}
On utilise la fonction wrapper \texttt{import\_dataset()} définie dans
le fichier \texttt{utility\_ML} pour importer les datasets d'avis et de
labels \texttt{dataset.csv} et \texttt{labels.csv}.

Une fois les datasets importés, on les fusionne dans un même dataframe
en utilisant la fonction \texttt{merge\_datasets()} définie dans le
fichier \texttt{utility\_ML}.

Enfin, on mélange les lignes du dataset obtenu d'une manière aléatoire
afin de mélanger les avis positifs et négatifs en utilisant la fonction
\texttt{shuffle\_dataset()} définie dans le fichier
\texttt{utility\_ML.py}.

\lstinputlisting{source/dataset_importation.py}
\VerbatimInput{output/dataset_importation.txt}

\hypertarget{pruxe9-traitement-des-donnuxe9es}{%
\section{Pré-traitement des
données}\label{pruxe9-traitement-des-donnuxe9es}}
On appelle la fonction \texttt{preprocess\_dataset(dataset)} définie
dans le fichier \texttt{utility\_ML.py} qui appelle la fonction
\texttt{preprocess(document)} sur la colonne \texttt{Avis} afin de
prétraiter les documents et les préparer à la vectorisation.

\hypertarget{pruxe9-traitement-dun-document}{%
\subsection{Pré-traitement d'un
document}\label{pruxe9-traitement-dun-document}}

La fonction \texttt{preprocess(document)} effectue les pré-traitements
suivants sur chaque document :
\begin{enumerate}
  \item remplacement des contractions par
  leurs expressions complètes équivalentes.
  \item suppression des balises
  HTML vides (\emph{e.g.~\texttt{\textless{}br\ /\textgreater{}},
  \texttt{\textless{}hr\ /\textgreater{}}, etc.})
  \item suppression des URLS
  \item nettoyage des débuts et fins des phrases
  (\texttt{help\ clean\_sentence\_anchors(document)} pour plus
  d'informations)
  \item tokenisation du document
  \item normalisation des tokens
  \item jointure des tokens normalisés afin de recréer le document, prêt
  maintenant à la vectorisation
\end{enumerate}

\hypertarget{pruxe9-traitement-des-tokens}{%
\subsection{Pré-traitement des
tokens}\label{pruxe9-traitement-des-tokens}}

La fonction \texttt{normalize(tokens)} effectue la normalisation des
tokens de la manière suivante :
\begin{enumerate}
  \item normalisation NFKD d'un token et
  encodage ASCII
  \item conversion en minuscule
  \item séparation des tokens
  collés par des caractères de ponctuation (\emph{e.g.~token1/token2,
  token1\_token2, etc.})
  \item remplacement des tokens désignant des chiffres
  par leurs équivalents en lettres
  \item suppression des caractères de
  ponctuation
  \item suppression des stopwords (liste des stopwords adaptée au
  contexte du projet) (\emph{cf.} \texttt{STOP\_WORDS} \emph{dans}
  \texttt{utility\_ML} \emph{pour plus d'informations})
  \item lemmatization
  des tokens en utilisant les tags du POS-Tagger
\end{enumerate}

Les fonctions \texttt{preprocess\_dataset(dataset)},
\texttt{preprocess(document)}, \texttt{normalize(tokens)} et toutes les
fonctions de pré-traitements y inclus sont toutes définies dans
\texttt{utility\_ML.py}.

\lstinputlisting{source/dataset_preprocessing.py}
\VerbatimInput{output/dataset_preprocessing.txt}

\hypertarget{visualisation-des-donnuxe9es}{%
\section{Visualisation des
données}\label{visualisation-des-donnuxe9es}}
Afin de visualiser les effets de pré-traitement on utilisera un
\textbf{WordCloud} permettant de visualiser les mots les plus fréquents
dans les avis positifs et négatifs. Cette visualisation permettra de
mieux configurer les fonctions de prétraitement, notamment la liste des
stopwords qui pourra être améliorée en y ajoutant les mots neutres
propres au domaine désigné par le dataset.

\lstinputlisting{source/negative_visualization.py}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{images/negative_opinions_frequent_words.png}
    \end{center}
    { \hspace*{\fill} \\}

\lstinputlisting{source/positive_visualization.py}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{images/positive_opinions_frequent_words.png}
    \end{center}
    { \hspace*{\fill} \\}

\hypertarget{vectorisation}{%
\section{Vectorisation}\label{vectorisation}}
Après le pré-traitement de chaque avis dans le dataset, on utilise la
technique \textbf{BOW} (\textbf{Bag of Words}) avec un
\texttt{TfidfVectorizer()} permettant d'obtenir la matrice des
fréquences des termes, en choisissant les mots ayant une fréquence de
document (\emph{i.e.~Document Frequency}) de 12, et en appliquant
l'algorithme \texttt{n-grams} pour 1 et 2 termes

\lstinputlisting{source/vectorizing.py}

\hypertarget{cross-validation-scores}{%
\section{Cross-validation
scores}\label{cross-validation-scores}}

Une fois la vectorisation effectuée, on prépare un ensemble de modèles à
tester (avec leurs paramètres par défaut) en utilisant une
cross-validation sur 10 partitions différentes du datasets et la
métrique \textbf{Accuracy} pour évaluer les performances. On calcule les
scores sur chaque partition ainsi que les scores moyens et leurs
déviations standards en utilisant la fonction
\texttt{cross\_val\_score()}. Le nombre de partitions et leur choix se
fait par le biais d'un \texttt{KFold} qui sera passé à la fonction
\texttt{cross\_val\_score()}.

Les modèles choisis pour effectuer les tests:
\begin{enumerate}
  \item \textbf{Logistic Regression}
  \item \textbf{Stochastic Gradient Descent Classifier}
  \item \textbf{Decision Tree Classifier}
  \item \textbf{Random Forest Classifier}
  \item \textbf{Gaussian Naive Bayes Classifier}
  \item \textbf{K Nearest Neighbors Classifier}
  \item \textbf{Linear SVM Classifier} (\textbf{SVM} with a \textbf{linear} kernel)
\end{enumerate}

Une fois les modèles testés, on choisira les meilleurs modèles (en
termes de score moyen et déviation standard) à calibrer avec un
\texttt{GridSearchCV}.

\lstinputlisting{source/cross_validation.py}
\VerbatimInput{output/cross_validation.txt}

%     \begin{Verbatim}[commandchars=\\\{\}]
% {\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{}CROSS VALIDATION USING ACCURACY METRIC}
%         \PY{c+c1}{\PYZsh{}choosing the data (opinions) and target (score) columns in the dataset}
%         \PY{n}{X} \PY{o}{=} \PY{n}{vectors}\PY{o}{.}\PY{n}{toarray}\PY{p}{(}\PY{p}{)}
%         \PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
%
%         \PY{c+c1}{\PYZsh{}dictionary containing the models to cross validate using their default parameters}
%         \PY{n}{models} \PY{o}{=} \PY{p}{\PYZob{}}
%             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LogisticRegression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}\PY{p}{,}
%             \PY{c+c1}{\PYZsh{}\PYZsq{}SGDClassifier\PYZsq{}: SGDClassifier(),}
%             \PY{c+c1}{\PYZsh{}\PYZsq{}DecisionTreeClassifier\PYZsq{}: DecisionTreeClassifier(),}
%             \PY{c+c1}{\PYZsh{}\PYZsq{}RandomForestClassifier\PYZsq{}: RandomForestClassifier(),}
%             \PY{c+c1}{\PYZsh{}\PYZsq{}GaussianNB\PYZsq{}: GaussianNB(),}
%             \PY{c+c1}{\PYZsh{}\PYZsq{}KNeighborsClassifier\PYZsq{}: KNeighborsClassifier(),}
%             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LinearSVC}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{LinearSVC}\PY{p}{(}\PY{p}{)}
%         \PY{p}{\PYZcb{}}
%         \PY{c+c1}{\PYZsh{}configuring the parameters used by the cross validation function}
%         \PY{n}{k\PYZus{}fold} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{CV\PYZus{}SEED}\PY{p}{)}
%
%         \PY{c+c1}{\PYZsh{}cross validation using accuracy metric}
%         \PY{c+c1}{\PYZsh{}for each defined model}
%         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{model} \PY{o+ow}{in} \PY{n}{models}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
%             \PY{n}{start\PYZus{}time} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
%             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross validation started at }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
%             \PY{n}{cv\PYZus{}score} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{k\PYZus{}fold}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{n}{CV\PYZus{}SCORING}\PY{p}{)}
%             \PY{n}{output} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}
%         \PY{l+s+s2}{    Time taken to complete cross validation of }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ seconds}
%         \PY{l+s+s2}{    Accuracy scores over 10 evaluations: }\PY{l+s+si}{\PYZob{}\PYZcb{}}
%         \PY{l+s+s2}{    Mean score: }\PY{l+s+si}{\PYZob{}\PYZcb{}}
%         \PY{l+s+s2}{    Standard deviation of scores: }\PY{l+s+si}{\PYZob{}\PYZcb{}}
%         \PY{l+s+s2}{    }\PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{name}\PY{p}{,} \PY{n}{time}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{start\PYZus{}time}\PY{p}{,} \PY{n}{cv\PYZus{}score}\PY{p}{,} \PY{n}{cv\PYZus{}score}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cv\PYZus{}score}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{p}{)}
%
%             \PY{n+nb}{print}\PY{p}{(}\PY{n}{output}\PY{p}{)}
% \end{Verbatim}

\hypertarget{ruxe9sultats-de-la-cross-validation}{%
\subsection{Résultats de la
cross-validation}\label{ruxe9sultats-de-la-cross-validation}}

En appliquant la cross-validation sur l'ensemble des modèles choisis, on
se retrouve avec les résultats suivants ordonnés par ordre décroissant
sur les scores moyens :

\begin{longtable}[]{@{}lll@{}}
\toprule
Modèle & Score moyen & Déviation standard\tabularnewline
\midrule
\endhead
LinearSVC & 92\% & 1\%\tabularnewline
SGDClassifier & 92\% & 1\%\tabularnewline
LogisticRegression & 91\% & 0.8\%\tabularnewline
GaussianNB & 84\% & 1\%\tabularnewline
RandomForestClassifier & 81\% & 1\%\tabularnewline
KNeighborsClassifier & 79\% & 1\%\tabularnewline
DecisionTreeClassifier & 75\% & 0.8\%\tabularnewline
\bottomrule
\end{longtable}

À partir de ce tableau, nous avons choisi le modèle \textbf{Logistic
Regression}, ayant un score d'accuracy de 91\% et 0.8\% de déviation
standard et le modèle \textbf{Linear SVM} ayant un score d'accuracy de
92\% et 1\% de déviation standard. On a pu également choisir le modèle
\textbf{Stochastic Gradient Descent} au lieu du modèle \textbf{SVM}
ayant un kernel linéaire.

Afin d'experimenter un peu, nous avons décider de choisir
\textbf{Gaussian Naive Bayes} aussi pour visualiser l'effet de choisir
des modèles probabilistes dans l'analyse des sentiments.

%     \begin{Verbatim}[commandchars=\\\{\}]
% {\color{incolor}In [{\color{incolor}44}]:} \PY{c+c1}{\PYZsh{}CROSS VALIDATION RESULTS}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:38:23.624361}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of LogisticRegression: 6.682977199554443 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.914 0.911 0.916 0.922 0.932 0.905 0.933 0.924 0.911 0.921]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.9189}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.008722958213817153}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:39:27.854962}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of SGDClassifier: 14.247564554214478 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.9   0.909 0.92  0.934 0.94  0.907 0.936 0.925 0.913 0.925]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.9209000000000002}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.01277849756426787}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:40:48.950553}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of DecisionTreeClassifier: 796.7198390960693 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.757 0.75  0.763 0.755 0.76  0.739 0.755 0.732 0.751 0.753]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.7515000000000002}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.008947066558375441}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:59:27.524247}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of RandomForestClassifier: 53.930598735809326 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.803 0.815 0.813 0.823 0.819 0.833 0.835 0.814 0.799 0.826]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.818}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.011135528725660019}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:56:18.964747}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of GaussianNB: 23.15500497817993 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.817 0.841 0.829 0.853 0.836 0.838 0.85  0.847 0.833 0.85 ]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.8394}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.010650821564555487}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 19:47:55.137561}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of KNeighborsClassifier: 2430.809322834015 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.795 0.793 0.805 0.796 0.799 0.778 0.815 0.775 0.817 0.78 ]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.7953}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.013849548729110253}
%          \PY{c+c1}{\PYZsh{}}
%          \PY{c+c1}{\PYZsh{} Cross validation started at 2019\PYZhy{}04\PYZhy{}18 12:56:42.120080}
%          \PY{c+c1}{\PYZsh{} }
%          \PY{c+c1}{\PYZsh{}     Time taken to complete cross validation of LinearSVC: 6.601022243499756 seconds}
%          \PY{c+c1}{\PYZsh{}     Accuracy scores over 10 evaluations: [0.913 0.915 0.918 0.926 0.944 0.908 0.938 0.92  0.923 0.925]}
%          \PY{c+c1}{\PYZsh{}     Mean score: 0.923}
%          \PY{c+c1}{\PYZsh{}     Standard deviation of scores: 0.010497618777608539}
% \end{Verbatim}

\hypertarget{calibrage-des-hyperparamuxe8tres-des-moduxe8les-en-utilisant-un-gridsearch}{%
\section{Calibrage des hyperparamètres des modèles en utilisant
un
GridSearch}\label{calibrage-des-hyperparamuxe8tres-des-moduxe8les-en-utilisant-un-gridsearch}}

Une fois les modèles choisis à partir de l'étape d'évaluation par
cross-validation, il faut trouver les meilleurs hyperparamètres
permettant de raffiner les régions de décision de chaque modèle afin
d'avoir les meilleurs prédictions possibles. Ceci est effectué par un
\texttt{GridSearchCV}, qui permet de tester différentes combinaisons des
valeurs des hyperparamètres fournis dans un dictionnaire, pour chaque
modèle.

De plus, \texttt{GridSearchCV} permet de répéter le processus sur
\emph{K} partitions, pour choisir les meilleurs résultats par
cross-validation. Nous choisirons ainsi de répéter le processus sur 5
partitions différentes du dataset et nous utiliserons la métrique
\textbf{Accuracy} pour évaluer les différents calibrages des modèles.

Pour le modèle \textbf{Logistic Regression}, les hyperparamètres à
calibrer sont:
\begin{description}
  \item[C:] la valeur de l'inverse de la
  régularization pour la régression (sauts de \(10^{-k}\) avec \(k \in [-4;4]\))
  \item[P:] la norme à choisir pour les pénalités (\(L_1\) et \(L_2\))
\end{description}

Pour le modèle \textbf{Gaussian Naive Bayes}, il n'existe pas de
hyperparamètres à calibrer sauf \texttt{priors} désignant les
probabilités au préalable estimées pour chacune des classes. Toutefois,
nous nous touchons pas à cet hyperparamètre afin qu'il s'adapte
dynamiquement au données.
(cf.~ \url{https://scikit-learn.org/stable/modules/generated/sklearn.naive\_bayes.GaussianNB.html})

\lstinputlisting{source/gridsearchcv.py}
\VerbatimInput{output/gridsearchcv.txt}

\hypertarget{ruxe9sultats-du-calibrage-avec-un-gridsearch}{%
\subsection{Résultats du calibrage avec un
GridSearch}\label{ruxe9sultats-du-calibrage-avec-un-gridsearch}}

En appliquant un \texttt{GridSearchCV} sur l'ensemble des modèles
candidats choisis, on se retrouve avec les résultats suivants ordonnés
par ordre décroissant sur les scores moyens :

\begin{longtable}[]{@{}lll@{}}
\toprule
Modèle & Score moyen & Meilleurs Résultats des
hyperparamètres\tabularnewline
\midrule
\endhead
LogisticRegression & 90\% & C = 11.288378916846883 ; penalty =
\(L_2\)\tabularnewline
LinearSVC & 90\% & C = 1\tabularnewline
\bottomrule
\end{longtable}

À partir de ce tableau, nous avons choisi le modèle \textbf{Logistic
Regression}, ayant un score d'accuracy de 90\% et les hyperparamètres
\texttt{C} et \texttt{penalty} calibrés de la manière suivante :
\(C = 1\) ; \(penalty = L_2\).

\hypertarget{cruxe9ation-dun-pipeline-pour-le-moduxe8le-logistic-regression}{%
\section{Création d'un Pipeline pour le modèle Logistic
Regression}\label{cruxe9ation-dun-pipeline-pour-le-moduxe8le-logistic-regression}}

Suite au calibrage des hyperparamètres des modèles candidats, on choisit
le meilleur modèle calibré avec les meilleurs hyperparamètres pour
l'apprentissage et nous créons un pipeline permettant d'enchaîner les
étapes de pré-traitement, de vectorisation et d'apprentissage.

Pour la vectorisation, on utilise la technique \textbf{BOW} (\textbf{Bag
of Words}) avec un \texttt{TfidfVectorizer()}. On commence par appliquer
les fonctions de prétraitement sur chaque document et effectue la
vectorisation pour obtenir la matrice des fréquences des termes, en
choisissant les mots ayant une fréquence de document
(\emph{i.e.~Document Frequency}) de 12, et en appliquant l'algorithme
\texttt{n-grams} pour 1 et 2 termes.

Pour l'apprentissage on utilise une instance du modèle choisit avec les
meilleurs valeurs trouvées pour les hyperparamètres calibrés, notamment
le modèle \textbf{Logistic Regression}.

Une fois le pipeline executé :
\begin{enumerate}
  \item on teste le modèle appris
  \item on affiche son score de la métrique \textbf{Accuracy} en utilisant la fonction \texttt{accuracy\_score()}
  \item on affiche sa matrice de confusion en utilisant la fonction \texttt{confusion\_matrix()}
  \item on affiche les scores des métriques \textbf{Precision}, \textbf{Recall}, \textbf{F1-Score} et \textbf{Support} en utilisant la fonction \texttt{classification\_report()}
\end{enumerate}

Enfin, on sauvegarde le modèle en utilisant la fonction \texttt{dump()}
du module \texttt{pickle}.

\lstinputlisting{source/lr_pipeline.py}
\VerbatimInput{output/lr_pipeline.txt}

\hypertarget{cruxe9ation-dun-pipeline-pour-le-moduxe8le-gaussian-naive-bayes}{%
\section{Création d'un Pipeline pour le modèle Gaussian Naive
Bayes}\label{cruxe9ation-dun-pipeline-pour-le-moduxe8le-gaussian-naive-bayes}}

Nous créons aussi un pipeline pour le modèle \textbf{Gaussian Naive
Bayes} en utilisant les mêmes paramètres utilisés pour la création du
pipeline du modèle \textbf{Logistic Regression}. À la différence du
modèle \textbf{Logistic Regression}, \textbf{Gaussian Naive Bayes}
travaille avec des \textbf{matrices denses} (\emph{i.e.~dense matrices})
et non pas des \textbf{matrices creuses} (\emph{i.e.~sparse matrices}).

Il faut ainsi utiliser un transformateur permettant d'effectuer cette
étape suite à l'étape de ``fitting'' du pipeline. On définit ainsi une
classe \texttt{DenseTransformer} héritant de la classe de base des
transformateurs de matrices du module \textbf{scikit-learn}
\texttt{TransformerMixin} accomplissant cette tâche et fournissant le
résultat à la phase d'apprentissage.

Une fois le pipeline executé :
\begin{enumerate}
  \item on teste le modèle appris
  \item on affiche son score de la métrique \textbf{Accuracy} en utilisant la fonction \texttt{accuracy\_score()}
  \item on affiche sa matrice de confusion en utilisant la fonction \texttt{confusion\_matrix()}
  \item on affiche les scores des métriques \textbf{Precision}, \textbf{Recall}, \textbf{F1-Score} et \textbf{Support} en utilisant la fonction \texttt{classification\_report()}
\end{enumerate}

Enfin, on sauvegarde le modèle en utilisant la fonction \texttt{dump()}
du module \texttt{pickle}.

\lstinputlisting{source/gnb_pipeline.py}
\VerbatimInput{output/gnb_pipeline.txt}
\end{document}
